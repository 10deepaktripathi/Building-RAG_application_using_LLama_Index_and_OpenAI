{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9W2NP_mTSmaD"
   },
   "source": [
    "# **Below dependencies needed to be installed ot run the code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "q9efInp3Wlup"
   },
   "outputs": [],
   "source": [
    "# !pip install pypdf\n",
    "# !pip install docx2txt\n",
    "# !pip install python-dotenv\n",
    "# !pip install \"unstructured[pdf]\"\n",
    "# !pip install \"unstructured[docx]\"\n",
    "# !pip install accelerate\n",
    "# !pip install  openai langchain sentence_transformers chromadb unstructured -q\n",
    "# !pip install -q transformers einops accelerate langchain bitsandbytes\n",
    "# !pip install accelerate\n",
    "# !pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lkHavErBXChp",
    "outputId": "f84e87d3-8fc7-40e7-8007-08759226c1d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import openai\n",
    "import re\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext, download_loader, load_index_from_storage, LLMPredictor\n",
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "from google.colab import drive\n",
    "from llama_index import get_response_synthesizer\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.indices.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.tools.query_engine import QueryEngineTool\n",
    "from llama_index.query_engine import SubQuestionQueryEngine\n",
    "\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "vector_directory = '/content/drive/MyDrive'\n",
    "directory = '/content/drive/MyDrive/oax'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WV9s3YfjGpBs"
   },
   "source": [
    "# **Load Documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShsGDtxSudUi",
    "outputId": "23eadcb5-2e2c-43d1-fc0d-9558fde00168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Documnets :  2\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "def load_docs(directory):\n",
    "    loader = DirectoryLoader(directory, recursive=False)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "path2 = directory\n",
    "langchain_documents = load_docs(path2)\n",
    "print(\"Total Documnets : \",len(langchain_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "Yw7_RxDplvck"
   },
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "documents=[]\n",
    "files = []\n",
    "for doc in langchain_documents:\n",
    "    file = doc.metadata['source'].split(\"/\")[-1].split(\".\")[0].lower()\n",
    "    doc.metadata['source'] = file\n",
    "    files.append(file)\n",
    "    documents.append(Document(text =doc.page_content , metadata=doc.metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VRMv2qKylvk7",
    "outputId": "60cd1f41-f80b-4935-ddb9-5f4f78324a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inputdocumentone', 'inputdocumenttwo']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "documents[0].metadata\n",
    "print(files)\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZhikRV-GgE5"
   },
   "source": [
    "# **Load LLM :** Note that, to run this code you need open-api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "qHVFl_3DpKjQ"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "openai.api_key = \"api-key\"\n",
    "model = 'text-davinci-003'\n",
    "llm = OpenAI(temperature=0, max_tokens=1024, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "EqUPeKH6crpM"
   },
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    chunk_size=1024,\n",
    "    llm=llm,\n",
    "    #callback_manager = CallbackManager([llama_debug]),\n",
    "    #embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_18pun8uEcN1"
   },
   "source": [
    "# **Document Indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxMeREnSKAzU",
    "outputId": "d75caf0a-dcd8-41e3-abad-be8a5c962c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector directory already exists. Going to load them from storage\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inputdocumentone': <llama_index.indices.vector_store.base.VectorStoreIndex at 0x78f733d4c040>,\n",
       " 'inputdocumenttwo': <llama_index.indices.vector_store.base.VectorStoreIndex at 0x78f733d4d030>}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index import TreeIndex, KeywordTableIndex, ListIndex\n",
    "from llama_index.indices.composability import ComposableGraph\n",
    "\n",
    "# Index summary\n",
    "index_summaries = dict()\n",
    "for i in range(len(documents)):\n",
    "    index_summaries[files[i]] = \"this index provides all the financial information stored in \"+ files[i] + \" file.\"\n",
    "\n",
    "# Calculate or load Index\n",
    "vector_directory = f\"{vector_directory}/vector/\"\n",
    "index_set = dict()\n",
    "try:\n",
    "  storage_context = StorageContext.from_defaults(persist_dir = vector_directory)\n",
    "  print(\"Vector directory already exists. Going to load them from storage\")\n",
    "  for file in files:\n",
    "    index_set[file] = load_index_from_storage(storage_context, file)\n",
    "\n",
    "except:\n",
    "  print(\"Indexing does not exist. Going to calculate\")\n",
    "  storage_context = StorageContext.from_defaults()\n",
    "  for i in range(len(documents)):\n",
    "    index = VectorStoreIndex.from_documents([documents[i]], service_context=service_context, storage_context=storage_context)\n",
    "    index.set_index_id(files[i])\n",
    "    index.storage_context.persist(vector_directory)\n",
    "    index_set[files[i]] = index\n",
    "\n",
    "index_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For complex queries below approach can be used, which devides your questios in multiple subquestions automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "5kP1mZ4eMVg0"
   },
   "outputs": [],
   "source": [
    "# query_engine_set = dict()\n",
    "# for key, index in index_set.items():\n",
    "#     query_engine_set[key] = index.as_query_engine(\n",
    "#                                                   #k=3,\n",
    "#                                                   node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.75)],\n",
    "#                                                   service_context=service_context\n",
    "#                                                   )\n",
    "\n",
    "# query_tools=[]\n",
    "# for key, index in query_engine_set.items():\n",
    "#     query_tool = QueryEngineTool.from_defaults(\n",
    "#         query_engine=query_engine_set[key],\n",
    "#         name=key,\n",
    "#         description=f\"Provides information about {key.split('.')[0]}\",\n",
    "#     )\n",
    "#     query_tools.append(query_tool)\n",
    "\n",
    "# query_engine = SubQuestionQueryEngine.from_defaults(query_engine_tools=query_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "Wkhxn2uJ_b3M"
   },
   "outputs": [],
   "source": [
    "def print_large(text, font_size=20):\n",
    "    text = re.sub('\\n','<br/>',text)\n",
    "    html_text = f\"<p style='font-size:{font_size}px'>{text}</p>\"\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(html_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "FCaCrG7X5x5t"
   },
   "outputs": [],
   "source": [
    "graph = ComposableGraph.from_indices(\n",
    "    KeywordTableIndex,\n",
    "    [index_set[key] for key in index_set],\n",
    "    [index_summaries[key] for key in index_summaries],\n",
    "    service_context=service_context,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.90)]\n",
    ")\n",
    "\n",
    "query_engine = graph.as_query_engine(service_context=service_context, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edRTSLcTR78I"
   },
   "source": [
    "# **QUESTIONS ANSWERS STARTS FROM HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CCUVvs0ypr7"
   },
   "source": [
    "# **QUESTION 1: What is an Acceptable Bank?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "id": "qMTDPTkU19eY",
    "outputId": "983e5f81-4017-4018-d1e9-154d1e6a7b16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font-size:20px'> An Acceptable Bank is a bank or financial institution which has a rating for its long-term unsecured and non credit-enhanced debt obligations of BBB- or higher by Standard & Poor's Rating Services or Fitch Ratings Ltd or Baa3 or higher by Moody's Investors Service Limited or a comparable rating from an internationally recognised credit rating agency; or any other bank or financial institution approved by the Agent.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"what is an Acceptable Banks in inputDocumentOne\")\n",
    "print_large(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThpQY4i7y2CH"
   },
   "source": [
    "#**QUESTION 2: What is Margin Definition?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "pLxiGGY0pKjd",
    "outputId": "13233939-4f29-4e13-d264-7f33257042e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font-size:20px'><br/>The Margin is defined as 300 (three hundred) basis points per annum from the Signing Date to the first Utilisation Date and, thereafter, as set out in the table below:<br/><br/>Months from the first Utilisation Date: Basis points per annum<br/>0-2: 300<br/>3-4: 375<br/>5-6: 425<br/>7 or more: 475<br/><br/>Provided that (to the extent that an Accordion Bridge Facility Commitment has been drawn), until the date on which the Target Accordion Commitment Condition is satisfied, the Margin applicable to the Accordion Bridge Facility shall be 300 (three hundred) basis points per annum and, from and including the date on which the Target Accordion Commitment Condition is satisfied, the Margin applicable to the Accordion Bridge Facility shall be as set out in the table above.<br/><br/>The table shows that the Margin applicable to the Accordion Bridge Facility is 300 basis points per annum from the Signing Date to the first Utilisation Date. After the first Utilisation Date, the Margin applicable to the Accordion Bridge Facility increases depending on the number of months from the first Utilisation Date, with the highest Margin being 475 basis points per annum for 7 or more months.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"Margin definition according to inputDocumentOne. describe the table as well\")\n",
    "print_large(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hG_tMtg3zAPA"
   },
   "source": [
    "#**QUESTION: What is governing law?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "pCaJOxutpKjg",
    "outputId": "e4b3b201-d191-437a-83d5-8c8a8759ad8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font-size:20px'> English law.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"governing law in inputDocumentOne under GOVERNING LAW AND ENFORCEMENT\")\n",
    "print_large(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyYtyfFAzJ4P"
   },
   "source": [
    "# **QUESTION: Fetach all defintitions from section 1.1 of inputDocumentTwo?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "I7bQbPou2sEU",
    "outputId": "c2220a82-e644-42e7-e7c1-f3446276450c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font-size:20px'><br/>The definition terms mentioned in section 1.1 of inputDocumentTwo are: Fee Letter, Final Maturity Date, Finance Document, Finance Lease, Finance Party, Financial Indebtedness, Financial Quarter, Financial Year, Funding Rate, General Meeting, Group, Group Structure Chart, Holding Company, VAT, Agent, Finance Party, Lender, Borrower, Investor, Party, Secured Party, Security Agent, Successors in title, Permitted assigns, Permitted transferees, Agreed form, Assets, Finance Document, Transaction Document, Agreement, Instrument, Group of Lenders, Guarantee, Indebtedness, Person, Regulation, Provision of law, Time of day, Central Bank Rate, SOFR Terms Supplement, Compounding Methodology Supplement, Daily Non-Cumulative Compounded SOFR, Cumulative Compounded SOFR, Interest Period, Default, Event of Default, Major Default, Insolvency Event.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Terms Fetched = 48\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"fetch all the definition terms mentioned in section 1.1 of inputDocumentTwo.\")\n",
    "print_large(str(response))\n",
    "print(\"Total Terms Fetched =\", len(str(response).split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JO1fArMMz3sa"
   },
   "source": [
    "Note that above answer can further be improved.I know it is not the best answer, but each experiment is costing me money as i am using open AI api. I tried using open sorece LLM, but my system is not very powerful enough to load those models and work with them. My google colab and kaggle GPU usage cota has already ran out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pamms85zXYj"
   },
   "source": [
    "# **QUESTION: What is Total Commitments means in inputDocumentTwo?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "sqvUkSxCVkkH",
    "outputId": "0f424d7c-2db4-4784-8d34-18199947e154"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font-size:20px'> Total Commitments means the aggregate Commitments amount of $267,000,000.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"what is Total Commitments means amount in inputDocumentTwo.\")\n",
    "print_large(str(response))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
